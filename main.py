import asyncio
import logging
import os
from typing import Dict, List
from aiogram import Bot, Dispatcher, types
from aiogram.types import Message
from aiogram.filters import Command
from dotenv import load_dotenv

from llm_functions import (
    llm_dispatcher, 
    llm_extractor, 
    llm_relevance_checker, 
    llm_answer_generator
)
from retrieving_utils import find_model_database, search_similar_models, hybrid_search

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞
BOT_TOKEN = os.getenv("BOT_TOKEN")
bot = Bot(token=BOT_TOKEN)
dp = Dispatcher()

# –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
user_history: Dict[int, List[str]] = {}

def get_user_history(user_id: int, max_messages: int = 3) -> List[str]:
    """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    return '\n'.join(user_history.get(user_id, [])[-max_messages:])

def add_user_message(user_id: int, message: str):
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é"""
    if user_id not in user_history:
        user_history[user_id] = []
    user_history[user_id].append(message)
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é 10 —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
    if len(user_history[user_id]) > 10:
        user_history[user_id] = user_history[user_id][-10:]

@dp.message(Command("start"))
async def start_handler(message: Message):
    welcome_text = """
üåü –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ —Å–ª—É–∂–±—É –ø–æ–¥–¥–µ—Ä–∂–∫–∏ "–õ—É—á—à–∏–µ –∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä—ã"! 

–Ø –≤–∞—à –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä–∞–º. –ú–æ–≥—É –ø–æ–º–æ—á—å –≤–∞–º —Å:
‚Ä¢ –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏ –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ
‚Ä¢ –ù–∞—Å—Ç—Ä–æ–π–∫–æ–π –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º
‚Ä¢ –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ–º –Ω–µ–ø–æ–ª–∞–¥–æ–∫
‚Ä¢ –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏

–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤–∞—à–µ–≥–æ –∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä–∞ –∏ –≤–∞—à –≤–æ–ø—Ä–æ—Å!
    """
    await message.answer(welcome_text)

@dp.message()
async def message_handler(message: Message):
    """–û—Å–Ω–æ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π"""
    user_id = message.from_user.id
    user_message = message.text
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
    add_user_message(user_id, user_message)
    
    try:
        # –≠—Ç–∞–ø 1: LLM-–¥–∏—Å–ø–µ—Ç—á–µ—Ä –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞
        recent_messages = get_user_history(user_id, 3)
        dispatcher_response = await llm_dispatcher(recent_messages)
        
        # –ï—Å–ª–∏ –¥–∏—Å–ø–µ—Ç—á–µ—Ä –º–æ–∂–µ—Ç –æ—Ç–≤–µ—Ç–∏—Ç—å —Å—Ä–∞–∑—É
        if dispatcher_response.get("type") == "direct_answer":
            await message.answer(dispatcher_response.get("answer", "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ –º–æ–≥—É –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å."))
            return
        
        # –ï—Å–ª–∏ –¥–∏—Å–ø–µ—Ç—á–µ—Ä –ø—Ä–æ—Å–∏—Ç —É—Ç–æ—á–Ω–∏—Ç—å –º–æ–¥–µ–ª—å
        if dispatcher_response.get("type") == "need_clarification":
            await message.answer(dispatcher_response.get("answer", "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Ç–æ—á–Ω–∏—Ç–µ –º–æ–¥–µ–ª—å –∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä–∞."))
            return
        
        # –ï—Å–ª–∏ –Ω—É–∂–µ–Ω –ø–æ–∏—Å–∫ –ø–æ –º–∞–Ω—É–∞–ª–∞–º
        if dispatcher_response.get("type") == "search_manual":
            # –£–≤–µ–¥–æ–º–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ –Ω–∞—á–∞–ª–µ –ø–æ–∏—Å–∫–∞
            await message.answer("üîç –ú–Ω–µ –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è –≤—Ä–µ–º—è –¥–ª—è –æ—Ç–≤–µ—Ç–∞. –ü–æ–¥–æ–∂–¥–∏—Ç–µ...")
            extraction_result = await llm_extractor(recent_messages)
            
            if not extraction_result:
                await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –º–æ–¥–µ–ª—å –∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä–∞ –∏ —Ç–µ–º—É –∑–∞–ø—Ä–æ—Å–∞.")
                return
            
            model_name = extraction_result.get("model")
            topic = extraction_result.get("topic")
            
            if not model_name or not topic:
                await message.answer("‚ùå –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –º–æ–¥–µ–ª—å –∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä–∞ –∏ –≤–∞—à –≤–æ–ø—Ä–æ—Å –±–æ–ª–µ–µ —á–µ—Ç–∫–æ.")
                return
            
            # –≠—Ç–∞–ø 3: –ü–æ–∏—Å–∫ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –ø–æ –º–æ–¥–µ–ª–∏
            vector_db_path = find_model_database(model_name)
            
            if not vector_db_path:
                # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –º–æ–¥–µ–ª–∏
                similar_models = search_similar_models(model_name)
                if similar_models:
                    models_text = "\n".join([f"‚Ä¢ {model}" for model in similar_models])
                    await message.answer(f"‚ùì –ú–æ–¥–µ–ª—å '{model_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –í–æ–∑–º–æ–∂–Ω–æ, –≤—ã –∏–º–µ–ª–∏ –≤ –≤–∏–¥—É:\n{models_text}")
                else:
                    await message.answer(f"‚ùå –ö–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä –º–æ–¥–µ–ª–∏ '{model_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –Ω–∞—à–µ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.")
                return
            
            # –≠—Ç–∞–ø 4: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
            chunks = hybrid_search(vector_db_path, topic)
            
            if not chunks:
                await message.answer("‚ùå –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–∞–π—Ç–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å.")
                return
            
            # –≠—Ç–∞–ø 5: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            is_relevant = await llm_relevance_checker(user_message, chunks)
            
            if not is_relevant:
                await message.answer("‚ùå –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –Ω–∞–π—Ç–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å.")
                return
            
            # –≠—Ç–∞–ø 6: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
            final_answer = await llm_answer_generator(user_message, chunks, model_name)
            
            if final_answer:
                await message.answer(f"‚úÖ {final_answer}")
            else:
                await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å.")
        
        else:
            await message.answer("‚ùå –ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ –º–æ–≥—É –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤–∞—à –∑–∞–ø—Ä–æ—Å.")
    
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        await message.answer("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞"""
    logging.info("–ë–æ—Ç –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è...")
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())